{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2ij3Q7VLbXQYo3Ot4kxMF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tchotaneu/Supervised_learning/blob/main/notion_Terminoly_fonctionLoss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication des fonctions de perte courantes à l'aide d'exemples simples**"
      ],
      "metadata": {
        "id": "2oyhCcRBcjwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS3hvj6JcYjo",
        "outputId": "02abc8e3-62a3-47d7-8672-71c4fdf5380b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09099999999999993\n",
            "0.15600000000000014\n"
          ]
        }
      ],
      "source": [
        "# Erreur quadratique moyenne - utilisée dans les problèmes de régression\n",
        "# Moyenne des distances au carré entre les valeurs réelles et les valeurs prédites\n",
        "# Cette valeur de perte est minimisée au cours du processus de formation d'un réseau neuronal.\n",
        "\n",
        "actual = [1.2, 2.3, 3, 4.5, 5.2, 6.3, 6.9, 8.4, 9.1, 9.9]\n",
        "predicted1 = [1.1, 2.1, 3.3, 4.2, 4.9, 6., 7.2, 8., 9.5, 10.2]\n",
        "predicted2 = [0.8, 2., 2.6, 4.8, 5.7, 6.1, 6.5, 7.8, 9.5, 9.6]\n",
        "\n",
        "def mean_squared_error(actual, predicted):\n",
        "\tsum_square_error = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tsum_square_error += (actual[i] - predicted[i])**2.0\n",
        "\tmean_square_error = sum_square_error/ len(actual)\n",
        "\treturn mean_square_error\n",
        "\n",
        "print(mean_squared_error(actual, predicted1))\n",
        "print(mean_squared_error(actual, predicted2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# entropie croisée (binaire) - également appelée perte logarithmique\n",
        "# Utilisée pour les problèmes de classification binaire. Peut être étendu aux problèmes de classification multiclasse. \n",
        "# Pénalité logarithmique basée sur la comparaison des classes réelles et prédites. \n",
        "# Une prédiction parfaite signifie une entropie croisée nulle.\n",
        "from numpy import mean\n",
        "from math import log\n",
        "\n",
        "actual_label = [0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1]\n",
        "predicted1 = [0.1, 0.9, 0.8, 0.7, 0.3, 0.2, 0.9, 0.4, 0.9, 0.99, 0.1, 0.8] \n",
        "predicted2 = [0.9, 0.1, 0.8, 0.7, 0.3, 0.2, 0.2, 0.4, 0.1, 0.99, 0.1, 0.6]  \n",
        "\n",
        "# calculer l'entropie croisée\n",
        "def cross_entropy(p, q):     #p est la valeur réelle et q est la valeur prédite\n",
        "\treturn -sum([p[i]*log(q[i]) for i in range(len(p))])\n",
        " \n",
        "#Calcul de l'entropie croisée pour chaque paire de données réelles et prédites\n",
        "predicted_prob = predicted2  #Test predicted 1 and 2\n",
        "\n",
        "results = list()\n",
        "for i in range(len(actual)):\n",
        " #Créer une liste pour chaque occurrence (binaire --> [Not, actual]). Peut être étendu à plusieurs classes.\n",
        "  actual_value = [1.0 - actual_label[i], actual_label[i]]  \n",
        "  #print(actual_value)\n",
        "  #Créer une liste pour chaque occurrence (binaire --> [Not, predicted]). Peut être étendu à plusieurs classes.\n",
        "  predicted_value = [1.0 - predicted_prob[i], predicted_prob[i]]\n",
        " #print(predicted_value)\n",
        "\n",
        "  # calculer l'entropie croisée :\n",
        "  ce = cross_entropy(actual_value, predicted_value)\n",
        "  print('actual=%.1f, predicted=%.1f --- cross_entropy: %.3f ' % (actual_label[i], predicted_prob[i], ce))\n",
        "  results.append(ce)\n",
        " \n",
        "# calculer l'entropie croisée moyenne\n",
        "mean_ce = mean(results)\n",
        "print('Average Cross Entropy: ', mean_ce)\n",
        "\n",
        "# Utilisez ce guide pour évaluer la perte au cours de votre processus de formation\n",
        "#Entropie croisée = 0,00 : Correspondance parfaite.\n",
        "#< 0.02 : Très bonne correspondance.\n",
        "#< 0.05 : Bonne.\n",
        "#< 0.20 : Acceptable.\n",
        "# > 0.30 : Pas bon.\n",
        "#> 1.00 : Mauvais.\n",
        "# > 2.00 : Horrible."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeyUxPpse3hk",
        "outputId": "1150d971-c93a-4e52-a135-5db3441d4b55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual=0.0, predicted=0.9 --- cross_entropy: 2.303 \n",
            "actual=1.0, predicted=0.1 --- cross_entropy: 2.303 \n",
            "actual=1.0, predicted=0.8 --- cross_entropy: 0.223 \n",
            "actual=1.0, predicted=0.7 --- cross_entropy: 0.357 \n",
            "actual=0.0, predicted=0.3 --- cross_entropy: 0.357 \n",
            "actual=0.0, predicted=0.2 --- cross_entropy: 0.223 \n",
            "actual=1.0, predicted=0.2 --- cross_entropy: 1.609 \n",
            "actual=0.0, predicted=0.4 --- cross_entropy: 0.511 \n",
            "actual=1.0, predicted=0.1 --- cross_entropy: 2.303 \n",
            "actual=1.0, predicted=1.0 --- cross_entropy: 0.010 \n",
            "Average Cross Entropy:  1.0197706141541614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entropie croisée avec Keras\n",
        "import numpy as np\n",
        "from keras import backend\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "actual_label = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1], [1, 1, 0, 0, 1]])\n",
        "\n",
        "#Identique à l'étiquette actuelle\n",
        "predicted = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1], [1, 1, 0, 0, 1]], dtype=np.float32)  \n",
        "\n",
        "#Classe 1 : proche de la réalité\n",
        "#Classe 2 : 1 erreur de classification (0,4 au lieu de 1, 2 au milieu à 0,5)\n",
        "#Classe 3 : 4 erreurs de classification\n",
        "\n",
        "predicted1 = np.array([[0.1, 0.8, 0.2, 0.9, 0.1], [0.4, 0.5, 0.5, 0.3, 0.7], [0.1, 0.2, 0.7, 0.6, 0.5]], dtype=np.float32) \n",
        "\n",
        "#Classe 1 : 3 erreurs de classement\n",
        "#Classe 2 : 0 erreur de classement\n",
        "#Classe 3 : 5 erreurs de classification\n",
        "\n",
        "predicted2 = np.array([[0.8, 0.3, 0.8, 0.8, 0.4], [0.6, 0.2, 0.8, 0.1, 0.6], [0.1, 0.3, 0.8, 0.9, 0.1]], dtype=np.float32) \n",
        "\n",
        "# Convert the arrays to keras variables\n",
        "y_true = backend.variable(actual_label)\n",
        "y_pred = backend.variable(predicted)\n",
        "y_pred1 = backend.variable(predicted1)\n",
        "y_pred2 = backend.variable(predicted2)\n",
        "\n",
        "# calculate mean cross-entropy\n",
        "mean_ce = backend.eval(binary_crossentropy(y_true, y_pred))\n",
        "mean_ce1 = backend.eval(binary_crossentropy(y_true, y_pred1))\n",
        "mean_ce2 = backend.eval(binary_crossentropy(y_true, y_pred2))\n",
        "print('Average Cross Entropy for pred: ', mean_ce)\n",
        "print('Average Cross Entropy for pred1: ', mean_ce1)\n",
        "print('Average Cross Entropy for pred2: ', mean_ce2)\n",
        "\n",
        "#En général, la perte est élevée pour toutes les classes, même si certaines classes sont plus faciles à classer. \n",
        "#Voir la perte pour la classe 2 dans pred1, nous voyons une valeur élevée de 0,6 malgré des résultats proches de la réalité. \n",
        "# La perte focale résout ce problème.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6r-Hv-DnpzZ",
        "outputId": "3ffccd27-81b3-4132-8298-5c47bde6b2dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Cross Entropy for pred:  [0. 0. 0.]\n",
            "Average Cross Entropy for pred1:  [0.1524736 0.6031868 1.3450863]\n",
            "Average Cross Entropy for pred2:  [1.0313632 0.3146596 1.9442326]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Focal loss\n",
        "from keras import backend\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "actual_label = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1], [1, 1, 0, 0, 1]])\n",
        "\n",
        "#Classe 1 : proche de la réalité\n",
        "#Classe 2 : 1 erreur de classification (0,4 au lieu de 1, 2 au milieu à 0,5)\n",
        "#Classe 3 : 4 erreurs de classification\n",
        "predicted1 = np.array([[0.1, 0.8, 0.2, 0.9, 0.1], [0.4, 0.5, 0.5, 0.3, 0.7], [0.1, 0.2, 0.7, 0.6, 0.5]], dtype=np.float32) \n",
        "\n",
        "# Convertir les tableaux en variables keras\n",
        "y_true = backend.variable(actual_label)\n",
        "y_pred1 = backend.variable(predicted1)\n",
        "\n",
        "# Focal loss function\n",
        "gamma=3.  #Lorsque gamma=0, la perte focale devrait être la même que l'entropie croisée. Essayez gamma=3. Un gamma plus élevé donne plus de poids aux classes mal classées.\n",
        "alpha=0.25  #\n",
        "def focal_loss_fixed(y_true, y_pred):\n",
        "   \n",
        "\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\treturn -backend.mean(alpha * backend.pow(1. - pt_1, gamma) * backend.log(pt_1)) - backend.mean((1 - alpha) * backend.pow(pt_0, gamma) * backend.log(1. - pt_0))\n",
        "\n",
        "c=1  #Class\n",
        "FL_class1 = focal_loss_fixed(y_true[0], y_pred1[0])\n",
        "FL_class2 = focal_loss_fixed(y_true[1], y_pred1[1])\n",
        "FL_class3 = focal_loss_fixed(y_true[2], y_pred1[2])\n",
        "\n",
        "print('(moyenne) Average Focal Loss pour la class1: ', FL_class1)\n",
        "print('(moyenne) Average Focal Loss pour  class2: ', FL_class2)\n",
        "print('(moyenne) Average Focal Loss pour  class3: ', FL_class3)\n",
        "\n",
        "#Lorsque gamma=0, FL=CL. Il est clair que la perte pour la deuxième classe est élevée bien qu'elle classifie presque correctement.\n",
        "#Lorsque gamma=3, le FL pour la classe 2 est faible et pourtant la perte pour la classe 3 est environ 7 fois plus élevée que celle de la classe 2.\n",
        "#Le réseau se concentre donc davantage sur la classe 3 pendant l'apprentissage, ce qui garantit de meilleurs résultats pour cette classe par rapport aux classes faciles à classer.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EeB4CCZqonm",
        "outputId": "c03f97f2-1e1b-42dd-bb44-229f7201d316"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(moyenne) Average Focal Loss pour la class1:  tf.Tensor(0.00039390582, shape=(), dtype=float32)\n",
            "(moyenne) Average Focal Loss pour  class2:  tf.Tensor(0.029150667, shape=(), dtype=float32)\n",
            "(moyenne) Average Focal Loss pour  class3:  tf.Tensor(0.22109523, shape=(), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}